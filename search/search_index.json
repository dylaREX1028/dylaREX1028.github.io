{"config":{"lang":["es"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Proyecto de programaci\u00f3n","text":"<p>Esta es la documentaci\u00f3n del proyecto de programaci\u00f3n de IE0405 - Modelos Probabil\u00edsticos de Se\u00f1ales y Sistemas.</p> <p>Los objetivos est\u00e1n en esta p\u00e1gina mientras que una introducci\u00f3n a los temas de recopilaci\u00f3n, procesamiento y modelado de datos est\u00e1n en p\u00e1ginas aparte. Finalmente est\u00e1n las instrucciones espec\u00edficas del proyecto.</p>"},{"location":"#objetivos","title":"Objetivos","text":"<p>Objetivo general</p> <p>Implementar una canalizaci\u00f3n de datos (pipeline) en tiempo real para procesamiento y an\u00e1lisis a partir de una fuente de datos externa, utilizando las herramientas computacionales de Python.</p>"},{"location":"#objetivos-especificos-de-programacion","title":"Objetivos espec\u00edficos de programaci\u00f3n","text":"<ol> <li>Configurar tareas peri\u00f3dicas</li> <li>Recopilar datos de un API web</li> <li>Procesar datos en formato JSON</li> <li>Utilizar bases de datos SQL</li> <li>Documentar resultados </li> </ol>"},{"location":"#objetivos-especificos-de-estadistica-y-probabilidad","title":"Objetivos espec\u00edficos de estad\u00edstica y probabilidad","text":"<ol> <li>Realizar an\u00e1lisis exploratorios de datos con estad\u00edstica descriptiva (media, varianza, etc.)</li> <li>Determinar modelos de probabilidad y sus par\u00e1metros</li> <li>Graficar datos y sus modelos</li> <li>Encontrar una expresi\u00f3n anal\u00edtica para una transformaci\u00f3n de variables aleatorias</li> <li>Comparar los datos de la variable transformada con el modelo anal\u00edtico</li> </ol>"},{"location":"#objetivos-especificos-de-aplicacion","title":"Objetivos espec\u00edficos de aplicaci\u00f3n","text":"<ol> <li>Explorar fuentes de datos en tiempo real para su recopilaci\u00f3n y an\u00e1lisis.</li> <li>Utilizar interfaces de programaci\u00f3n de aplicaciones (API) de forma program\u00e1tica para obtener datos de fuentes externas.</li> <li>Utilizar administradores de tareas (Celery Worker) y planificadores de tareas (Celery Beat) para ejecutar tareas peri\u00f3dicas.</li> <li>Utilizar un manejador de bases de datos (SQLite3, PostgreSQL) y un mapeador de objetos relacional (SQLAlchemy) para interactuar con bases de datos.</li> <li>Procesar los datos obtenidos para tratamiento y an\u00e1lisis.</li> <li>Utilizar herramientas estad\u00edsticas de Python para hacer an\u00e1lisis estad\u00edstico descriptivo y modelado probabil\u00edstico de los datos recopilados.</li> <li>Graficar los datos recopilados y sus an\u00e1lisis para visualizaci\u00f3n y an\u00e1lisis preliminar.</li> <li>Crear documentaci\u00f3n del proyecto en forma de p\u00e1gina web para presentaci\u00f3n al p\u00fablico en general.</li> </ol>"},{"location":"#sobre-la-documentacion","title":"Sobre la documentaci\u00f3n","text":"<p>Esta documentaci\u00f3n est\u00e1 creada con Material for MkDocs, una plataforma ampl\u00edsima con m\u00faltiples opciones de formato.</p> <p>En el archivo <code>mkdocs.yml</code> est\u00e1 la configuraci\u00f3n b\u00e1sica de esta documentaci\u00f3n, la cual debe ser modificada (especialmente la navegaci\u00f3n) para incluir las secciones de la documentaci\u00f3n del proyecto y sus resultados.</p> <p>En la carpeta <code>img/</code> pueden colocar im\u00e1genes como gr\u00e1ficas y similares.</p> <p>Pueden agregar la estructura de archivos y carpetas que sea necesaria.</p> <p>Contenidos de la documentaci\u00f3n del proyecto</p> <p>Para la documentaci\u00f3n de su proyecto, deben eliminar los textos del enunciado y solamente agregar la explicaci\u00f3n propia de su trabajo. Eso incluye esta secci\u00f3n y las de recopilaci\u00f3n, procesamiento y otras.</p>"},{"location":"atributos/","title":"R\u00fabricas de evaluaci\u00f3n","text":""},{"location":"atributos/#atributo-uh01","title":"Atributo UH01","text":"<p>Utilizaci\u00f3n de herramientas modernas de ingenier\u00eda: utiliza herramientas modernas y pertinentes para las diferentes fases de desarrollo de un proyecto.</p>"},{"location":"atributos/#recopilacion-de-datos","title":"Recopilaci\u00f3n de datos","text":"<p>Utiliza herramientas computacionales para obtener datos masivos a partir de fuentes diversas, incluyendo archivos locales o bases de datos y otras fuentes externas como servidores remotos y APIs. El planteamiento del proyecto incluye distintas fuentes de datos para an\u00e1lisis. Herramientas t\u00edpicas incluyen paquetes de Python como \u201crequests\u201d para extraer datos de APIs o SQLAlchemy para interactuar con bases de datos.</p> <ul> <li>Supera las expectativas: La implementaci\u00f3n es capaz de obtener datos de diversas fuentes sin vicios tales como importaci\u00f3n redundante, mal manejo de errores o p\u00e9rdida de datos.</li> <li>Cumple con las expectativas: La implementaci\u00f3n es capaz de obtener datos de todas las fuentes, pero no hace un manejo apropiado de errores o hace importaciones innecesarias.</li> <li>Marginal: La implementaci\u00f3n es capaz de obtener datos de algunas fuentes, solamente.</li> <li>Por debajo de las expectativas: La implementaci\u00f3n no es capaz de obtener datos de ninguna de las fuentes indicadas.</li> </ul>"},{"location":"atributos/#procesamiento-de-datos","title":"Procesamiento de datos","text":"<p>Utiliza herramientas computacionales para limpieza y filtrado de datos masivos y utiliza conocimientos estad\u00edsticos como criterio para selecci\u00f3n y eliminaci\u00f3n de datos espurios o aberrantes. La mayor parte de datos reales contienen este tipo de datos. El planteamiento del proyecto incluye fuentes de datos reales. Herramientas t\u00edpicas incluyen paquetes de Python como Pandas para ordenamiento de los datos.</p> <ul> <li>Supera las expectativas: La implementaci\u00f3n hace una limpieza de datos y un an\u00e1lisis estad\u00edstico descriptivo de los datos recopilados y despliega los resultados. Lo hace de forma correcta seg\u00fan est\u00e1 establecido en la columna de criterios.</li> <li>Cumple con las expectativas: La implementaci\u00f3n hace una limpieza de datos y un an\u00e1lisis estad\u00edstico descriptivo de los datos recopilados y despliega los resultados, pero omite alguna indicaci\u00f3n establecida en la columna de criterios.</li> <li>Marginal: La implementaci\u00f3n omite alguna de las tareas de limpieza de datos o de an\u00e1lisis estad\u00edstico descriptivo de los datos recopilados o del despliegue de los resultados.</li> <li>Por debajo de las expectativas: La implementaci\u00f3n no hace ni una limpieza de datos ni un an\u00e1lisis estad\u00edstico descriptivo de los datos recopilados.</li> </ul>"},{"location":"atributos/#visualizacion-de-datos","title":"Visualizaci\u00f3n de datos","text":"<p>Utiliza herramientas computacionales para crear gr\u00e1ficas relevantes de datos masivos. Herramientas t\u00edpicas incluyen paquetes de Python como Matplotlib, Seaborn o Plotly para gr\u00e1ficos bidimensionales y tridimensionales, con una gran cantidad de opciones de configuraci\u00f3n.</p> <ul> <li>Supera las expectativas: La implementaci\u00f3n utiliza gr\u00e1ficas relacionales, de distribuci\u00f3n o categ\u00f3ricas, seg\u00fan los tipos de datos disponibles. Las gr\u00e1ficas son visualmente apropiadas seg\u00fan criterios t\u00edpicos de ingenier\u00eda (rotulaci\u00f3n, escala, composici\u00f3n visual).</li> <li>Cumple con las expectativas: La implementaci\u00f3n utiliza gr\u00e1ficas relacionales, de distribuci\u00f3n o categ\u00f3ricas, seg\u00fan los tipos de datos disponibles, pero las gr\u00e1ficas no son visualmente apropiadas seg\u00fan criterios t\u00edpicos de ingenier\u00eda (rotulaci\u00f3n, escala, composici\u00f3n visual).</li> <li>Marginal: La implementaci\u00f3n no utiliza gr\u00e1ficas relacionales, de distribuci\u00f3n o categ\u00f3ricas, seg\u00fan los tipos de datos disponibles.</li> <li>Por debajo de las expectativas: La implementaci\u00f3n no utiliza tipos de gr\u00e1ficas pertinentes para los tipos de datos disponibles, ni las gr\u00e1ficas son visualmente apropiadas seg\u00fan criterios t\u00edpicos de ingenier\u00eda (rotulaci\u00f3n, escala, composici\u00f3n visual).</li> </ul>"},{"location":"atributos/#atributo-uh02","title":"Atributo UH02","text":"<p>Utilizaci\u00f3n de herramientas modernas de ingenier\u00eda: utiliza nuevas t\u00e9cnicas, herramientas o aplicaciones seg\u00fan las necesidades y oportunidades que presenta el desarrollo de un proyecto.</p>"},{"location":"atributos/#solucion-funcional","title":"Soluci\u00f3n funcional","text":"<p>Resuelve el problema con scripts de programaci\u00f3n</p> <ul> <li>Supera las expectativas: Con un conjunto de datos de prueba, el programa devuelve los resultados esperados, incluyendo pruebas con datos inv\u00e1lidos.</li> <li>Cumple con las expectativas: Con un conjunto de datos de prueba v\u00e1lidos, el programa devuelve los resultados esperados.</li> <li>Marginal: Uno o m\u00e1s de los resultados con datos de prueba est\u00e1n incorrectos.</li> <li>Por debajo de las expectativas: El programa no devuelve una respuesta.</li> </ul>"},{"location":"atributos/#convenciones","title":"Convenciones","text":"<p>Se adhiere a las convenciones de escritura de c\u00f3digo.</p> <ul> <li>Supera las expectativas: La revisi\u00f3n autom\u00e1tica del c\u00f3digo no reporta ning\u00fan error en las convenciones de sintaxis del c\u00f3digo.</li> <li>Cumple con las expectativas: La revisi\u00f3n autom\u00e1tica del c\u00f3digo reporta menos de cinco errores en las convenciones de sintaxis del c\u00f3digo.</li> <li>Marginal: La revisi\u00f3n autom\u00e1tica del c\u00f3digo reporta menos de diez errores en las convenciones de sintaxis del c\u00f3digo.</li> <li>Por debajo de las expectativas: La revisi\u00f3n autom\u00e1tica del c\u00f3digo reporta m\u00e1s de diez errores en las convenciones de sintaxis del c\u00f3digo.</li> </ul>"},{"location":"atributos/#documentacion","title":"Documentaci\u00f3n","text":"<p>Documenta la funcionalidad del paquete desarrollado.</p> <ul> <li>Supera las expectativas: La documentaci\u00f3n especifica claramente las funcionalidades existentes y adem\u00e1s es amplia en la teor\u00eda que respalda la soluci\u00f3n.</li> <li>Cumple con las expectativas: La documentaci\u00f3n especifica claramente las funcionalidades existentes.</li> <li>Marginal: La documentaci\u00f3n est\u00e1 completa, pero presenta errores de escritura (ortograf\u00eda, gram\u00e1tica).</li> <li>Por debajo de las expectativas: La documentaci\u00f3n est\u00e1 incompleta.</li> </ul>"},{"location":"atributos/#herramientas","title":"Herramientas","text":"<p>Utiliza las herramientas de software indicadas para el proyecto.</p> <ul> <li>Supera las expectativas: Desarrollo en un entorno local (computadora personal) configurado para el lenguaje de programaci\u00f3n y uso de herramientas (Git, editor, etc.)</li> <li>Cumple con las expectativas: Desarrollo en un entorno local sin una configuraci\u00f3n completa para el lenguaje de programaci\u00f3n.</li> <li>Marginal: Desarrollo en un entorno remoto (servidor web) que no fue configurado localmente para el lenguaje de programaci\u00f3n.</li> <li>Por debajo de las expectativas: No sigui\u00f3 las especificaciones de uso del lenguaje y sus herramientas y no puede desarrollar y ejecutar c\u00f3digo.</li> </ul>"},{"location":"atributos/#paquete","title":"Paquete","text":"<p>Desarrolla una soluci\u00f3n para un problema y entrega un paquete de Python desarrollado en el semestre.</p> <ul> <li>Supera las expectativas: Es posible para una persona usuaria instalar y utilizar el paquete. Adem\u00e1s, todos los errores y advertencias de uso del paquete est\u00e1n se\u00f1alados.</li> <li>Cumple con las expectativas: Es posible para una persona usuaria instalar y utilizar el paquete.</li> <li>Marginal: Es posible la instalaci\u00f3n del paquete, pero no funciona seg\u00fan las especificaciones.</li> <li>Por debajo de las expectativas: La instalaci\u00f3n del paquete es infructuosa y no es posible probarlo.</li> </ul>"},{"location":"atributos/#atributo-te02","title":"Atributo TE02","text":"<p>Trabajo individual y en equipo: Desempe\u00f1a el rol de trabajo de acuerdo con las expectativas establecidas por el equipo y las demandas propias del trabajo o proyecto.</p>"},{"location":"atributos/#presentacion","title":"Presentaci\u00f3n","text":"<p>Explica apropiadamente el aporte de su trabajo dentro del proyecto.</p> <ul> <li>Supera las expectativas: Presenta apropiadamente los resultados de su trabajo y lo hace en conexi\u00f3n con el proyecto global.</li> <li>Cumple con las expectativas: Presenta apropiadamente los resultados de su trabajo, pero no lo hace en conexi\u00f3n con el proyecto global.</li> <li>Marginal: Presenta de forma deficiente los resultados de su trabajo o no lo hace en conexi\u00f3n con el proyecto global.</li> <li>Por debajo de las expectativas: No presenta apropiadamente los resultados de su trabajo.</li> </ul>"},{"location":"atributos/#desarrollo-colaborativo","title":"Desarrollo colaborativo","text":"<p>Utiliza las herramientas apropiadas para el desarrollo colaborativo de software, en este caso Git y GitHub o repositorio remoto similar.</p> <ul> <li>Supera las expectativas: Su participaci\u00f3n es evidente en el repositorio de GitHub del proyecto, siguiendo buenas pr\u00e1cticas de manejo de versiones y documentaci\u00f3n.</li> <li>Cumple con las expectativas: Su participaci\u00f3n es evidente en el repositorio de GitHub del proyecto, pero no sigue buenas pr\u00e1cticas de manejo de versiones y documentaci\u00f3n.</li> <li>Marginal: Su participaci\u00f3n no es evidente en el repositorio de GitHub del proyecto, y no sigue buenas pr\u00e1cticas de manejo de versiones y documentaci\u00f3n.</li> <li>Por debajo de las expectativas: No participa del desarrollo colaborativo del proyecto.</li> </ul>"},{"location":"instrucciones/","title":"Enunciado del proyecto","text":""},{"location":"instrucciones/#instrucciones","title":"Instrucciones","text":""},{"location":"instrucciones/#configuracion","title":"Configuraci\u00f3n","text":"<p>Siguiendo las instrucciones de esta documentaci\u00f3n y el archivo <code>README.md</code> instalar y ejecutar localmente el proyecto. Tambi\u00e9n, habilitar el control de versiones con Git y GitHub para todo el equipo en los repositorios de MPSS-EIE.</p>"},{"location":"instrucciones/#fuente-de-datos","title":"Fuente de datos","text":"<p>En el sitio web Kalouk estar\u00e1 disponible un API, disponible en el siguiente endpoint:</p> <ul> <li>https://kalouk.xyz/api/datos</li> </ul> <p>Cada grupo har\u00e1 solicitudes en este endpoint con el par\u00e1metro <code>grupo</code>. Si un grupo es, por ejemplo, el 000, entonces la solicitud de datos es:</p> <pre><code>GET https://kalouk.xyz/api/datos?grupo=000\n</code></pre> <p>Esto devolver\u00e1 un conjunto de datos con un formato por determinar. Con la recopilaci\u00f3n de estos datos inicia el proyecto.</p>"},{"location":"instrucciones/#presentacion-de-avance","title":"Presentaci\u00f3n de avance","text":"<p>Valor: 5%</p> <p>En la documentaci\u00f3n web deben presentar:</p> <ol> <li>(1%) Modelos de la base de datos (<code>models.py</code>) y tareas de recolecci\u00f3n de datos (<code>tasks.py</code>) </li> <li>(1%) Recolecci\u00f3n preliminar de datos (al menos 12 horas continuas) en la base de datos </li> <li>An\u00e1lisis exploratorio de los datos<ul> <li>(1%) Gr\u00e1ficas descriptivas de <code>variable_1</code> y <code>variable_2</code> (histogramas y otros, si aplica) </li> <li>(1%) Modelos de probabilidad para los datos donde aplica y gr\u00e1fica sobre el histograma de los datos </li> <li>(1%) Momentos de los modelos (promedio, varianza, desviaci\u00f3n est\u00e1ndar, inclinaci\u00f3n, kurtosis) </li> </ul> </li> </ol> <p>Notas - Todo el c\u00f3digo debe cumplir con PEP 8 y ser\u00e1 evaluado usando, por ejemplo, <code>$ flake8 tasks.py</code>. - El desarrollo debe estar ampliamente comentado. - La buena ortograf\u00eda y gram\u00e1tica son esenciales.</p>"},{"location":"instrucciones/#presentacion-del-reporte-final","title":"Presentaci\u00f3n del reporte final","text":"<p>Valor: 15%</p> <p>En formato por definir, cada equipo presenta:</p> <ol> <li>Documentaci\u00f3n completa (5%)<ul> <li>Todo lo del avance, mejorado si es el caso</li> <li>Especificaci\u00f3n de la pregunta de investigaci\u00f3n</li> </ul> </li> <li>Respuesta a la pregunta de investigaci\u00f3n (5%)<ul> <li>Modelado de los datos obtenidos</li> <li>Resultados estad\u00edsticos (correlaciones, etc.)</li> </ul> </li> <li>An\u00e1lisis y conclusiones (5%)</li> </ol>"},{"location":"modelos/","title":"Modelos de probabilidad de los datos","text":"<p>Una parte central del proyecto es modelar estad\u00edsticamente los datos con distribuciones de probabilidad.</p> <p>En el <code>PyX</code> n\u00famero 5 Py5 hay una discusi\u00f3n sobre modelado de datos con SciPy y Fitter.</p> <p>En general, con el m\u00f3dulo <code>stats</code> del paquete SciPy es posible encontrar los par\u00e1metros de mejor ajuste para una distribuci\u00f3n particular, utilizando el m\u00e9todo <code>fit()</code> de las clases de variables aleatorias. Por ejemplo, para una distribuci\u00f3n normal:</p> <pre><code>from scipy import stats\n\nparams = stats.norm.fit(data)\n\nprint(params)\n</code></pre> <p>donde <code>data</code> es un conjunto de datos univariados.</p>"},{"location":"procesamiento/","title":"Procesamiento de datos","text":""},{"location":"procesamiento/#procesamiento-y-analisis-descriptivo-con-pandas","title":"Procesamiento y an\u00e1lisis descriptivo con Pandas","text":"<p>En el <code>PyX</code> n\u00famero 2 Py2 hay una amplia discusi\u00f3n sobre Pandas.</p> <p>Aqu\u00ed basta con decir que Pandas es el equivalente program\u00e1tico de Microsoft Office Excel y otros programas de ofim\u00e1tica de hojas de c\u00e1lculo, como Google Spreadsheets y LibreOffice Calc.</p> <p>Esto en el sentido de que Pandas manipula datos tabulares (filas y columnas, y en ese sentido planos) por medio del objeto <code>DataFrame</code>, que ser\u00eda equivalente a una pesta\u00f1a u hoja de Excel. Sobre los datos en este <code>DataFrame</code> es posible hacer todo tipo de operaciones y aplicar todo tipo de funciones, al igual que en Excel. </p> <p>Quiz\u00e1 las ventajas de Pandas son la posibilidad de trabajar con grandes cantidades de datos (limitados solamente por la memoria de la computadora) con mayor rendimiento y eficiencia. Excel tiene limitaciones de filas (1.048.576) y columnas (16.384, XFD) y su desempe\u00f1o se deteriora considerablemente al aproximarse a estos l\u00edmites. Tambi\u00e9n Pandas permite la integraci\u00f3n total con los m\u00faltiples paquetes de Python para crear flujos automatizados de procesamiento de datos, incluyendo aprendizaje autom\u00e1tico e interfaces de entrada y salida (sensores, actuadores, etc.).</p> <p>Adem\u00e1s, por supuesto, Pandas es de c\u00f3digo abierto y gratis.</p>"},{"location":"procesamiento/#visualizacion-de-datos-con-matplotlib","title":"Visualizaci\u00f3n de datos con Matplotlib","text":"<p>En el <code>PyX</code> n\u00famero 3 Py3 hay una discusi\u00f3n sobre los conceptos b\u00e1sicos de graficaci\u00f3n con Matplotlib.</p> <p>Matplotlib es popular y poderoso, pero no es la \u00fanica opci\u00f3n de graficaci\u00f3n en Python. Otras opciones populares y con buena documentaci\u00f3n son:</p> <ul> <li>Seaborn: basada en Matplotlib pero enfocada en gr\u00e1ficos estad\u00edsticos</li> <li>Plotly: sintaxis amigable y disponible para varios lenguajes</li> </ul>"},{"location":"recopilacion/","title":"Recopilaci\u00f3n y almacenamiento de datos","text":"<p>El an\u00e1lisis de datos comienza con la recopilaci\u00f3n de datos. Podr\u00edamos separar la recopilaci\u00f3n en dos grandes paradigmas:</p> <ul> <li>Procesamiento por lotes (batch processing): consiste en la recolecci\u00f3n de una gran cantidad de datos hist\u00f3ricos, t\u00edpicamente una sola vez, o con una frecuencia tan baja que cada recopilaci\u00f3n tiene una gran cantidad de datos. Ejemplos: los \"famosos\" datos de pasajeros del Titanic, los cuales necesariamente fueron recolectados una sola vez, o la informaci\u00f3n que utiliza YouTube o Netflix para entrenar sus sistemas de recomendaciones que, aunque son actualizados aproximadamente cada 24 horas, contienen millones de nuevas interacciones.</li> <li>Procesamiento en tiempo real (real-time processing): consiste en la recolecci\u00f3n de datos al momento de su ocurrencia, esto es, basado en eventos (event-driven) o con una frecuencia de recopilaci\u00f3n tan alta que solamente algunos pocos nuevos datos, o ninguno, son obtenidos en cada muestreo. Ejemplos: datos sobre terremotos, mercados de valores o de redes de sensores recopilados cada 10 segundos.</li> </ul> <p>En medio de ambos hay una \"zona gris\" a menudo llamada procesamiento en tiempo casi real (quasi real-time processing) que captura la din\u00e1mica del sistema sin responder directamente a eventos o a una alt\u00edsima frecuencia. Ejemplos: telemetr\u00eda y rastreo en veh\u00edculos de transporte p\u00fablico, que actualizan datos cada 15 o 20 segundos, lo suficiente para tener una buena estimaci\u00f3n de su posici\u00f3n, pero no totalmente \"en tiempo real\".</p> <p>La definici\u00f3n var\u00eda seg\u00fan el fen\u00f3meno analizado, que puede tener cambios muy frecuentes o no.</p> <p>Definici\u00f3n informal de procesamiento en tiempo real</p> <p>Un flujo de datos en el cual el procesamiento de una nueva muestra inicia en el momento de su llegada y concluye antes de la llegada de la siguiente muestra o evento es un procesamiento en tiempo real.</p>"},{"location":"recopilacion/#y-de-donde-vienen-estos-datos","title":"\u00bfY de d\u00f3nde vienen estos datos?","text":"<p>Los datos pueden venir de un solo archivo (ejemplo, un <code>.xlsx</code> o <code>.csv</code>), directamente de un sensor (ejemplo, un Arduino con un sensor de temperatura conectado a la computadora), o de una base de datos externa, siguiendo varios modelos de comunicaci\u00f3n posibles, explicados a continuaci\u00f3n.</p>"},{"location":"recopilacion/#modelos-de-comunicacion","title":"Modelos de comunicaci\u00f3n","text":"<p>Algunos de los modelos de comunicaci\u00f3n para compartir datos entre sistemas son:</p> <ul> <li>Solicitud/respuesta: donde una solicitud del cliente interact\u00faa con los recursos de un servidor que devuelve una respuesta. Ejemplo: HTTP (el famoso \"404 Not Found\") o las interfaces de programaci\u00f3n de aplicaciones web (API, Application Programming Interface) que operan sobre HTTP y conectan distintos servicios. </li> <li>Publicaci\u00f3n/suscripci\u00f3n: donde un productor publica un mensaje que coloca en un canal sobre un t\u00f3pico y un intermediador de mensajes lo distribuye a todos los procesos que est\u00e1n suscritos. Ejemplo: el monitoreo de eventos en la agricultura de precisi\u00f3n con una red de sensores conectada con MQTT. </li> <li>WebSockets: donde hay un canal de comunicaci\u00f3n bidireccional con comunicaci\u00f3n persistente. Ejemplo: cualquier aplicaci\u00f3n de chat (WhatsApp, Telegram, etc.) o videojuegos en l\u00ednea. A diferencia de los WebSockets, HTTP es una conexi\u00f3n no persistente.</li> <li>Otros</li> </ul> <p>Una de las soluciones m\u00e1s populares es obtener datos de fuentes externas, y hacerlo por medio de una interfaz de programaci\u00f3n de aplicaciones (API). Ver secci\u00f3n m\u00e1s adelante.</p>"},{"location":"recopilacion/#donde-son-almacenados-los-datos","title":"\u00bfD\u00f3nde son almacenados los datos?","text":"<p>Luego, el an\u00e1lisis de datos t\u00edpicamente contin\u00faa con el almacenamiento de datos despu\u00e9s de la recopilaci\u00f3n. Las bases de datos ofrecen almacenamiento permanente y son una soluci\u00f3n en el caso de grandes cantidades de datos.</p> <p>Nota: no siempre es necesario almacenar los datos de esta forma. A menudo es suficiente hacer el an\u00e1lisis de los datos y luego descartarlos.</p> <p>Hay distintos tipos de bases de datos y las bases de datos relacionales son las m\u00e1s comunes.</p>"},{"location":"recopilacion/#bases-de-datos-relacionales","title":"Bases de datos relacionales","text":"<p>Son datos tabulares -y por tanto \"planos\" y \"no anidados\"- en tablas con columnas, tambi\u00e9n llamadas campos (fields), y filas, tambi\u00e9n llamadas registros (records). Cada tabla tiene una llave primaria (PK, primary key) que identifica de forma \u00fanica cada registro. Las tablas est\u00e1n relacionadas entre s\u00ed (de ah\u00ed el nombre relacional) con llaves for\u00e1neas (FK, foreign key) que hacen referencia a un registro de otra tabla, creando una estructura l\u00f3gica entre las tablas de una misma base de datos.</p> <p>En el siguiente diagrama entidad-relaci\u00f3n (ERD) simplificado, una tabla tiene datos de estudiantes, otra tabla tiene datos de los cursos y una tercera tabla que vincula cursos con estudiantes (relaci\u00f3n muchos-a-muchos, many-to-many) con llaves for\u00e1neas a las dos tablas anteriores.</p> <pre><code>---\ntitle: Ejemplo de base de datos\n---\nerDiagram\n    ESTUDIANTE }o--o{ MATRICULA : matricula\n    ESTUDIANTE {\n        string estudiante_id PK\n        string nombre\n        int edad\n        float promedio\n    }\n    CURSO {\n        string curso_id PK\n        string nombre\n    }\n    MATRICULA }o--o{ CURSO : matricula\n    MATRICULA {\n        string estudiante_id FK\n        string curso_id FK\n        integer ciclo\n    }</code></pre> <p>Las bases de datos relacionales m\u00e1s utilizadas son tipo SQL (Structured Query Language), que utilizan un lenguaje especial para hacer consultas a la base de datos. Por ejemplo:</p> <pre><code>SELECT nombre, edad FROM estudiantes WHERE id = B00000;\n</code></pre> <p>devuelve los datos <code>nombre</code> y <code>edad</code> (pero no <code>promedio</code>) del carn\u00e9 B00000 en la tabla <code>estudiantes</code>.</p> <p>En general, las bases de datos tienen transacciones del tipo: lectura, creaci\u00f3n, actualizaci\u00f3n y eliminaci\u00f3n de registros (CRUD, Create, Read, Update, Delete).</p> <p>Los sistemas de administraci\u00f3n de bases de datos (DBMS, Data Base Management System) m\u00e1s populares son PostgreSQL, SQLite3, MySQL, MariaDB, Oracle y otros.</p>"},{"location":"recopilacion/#que-haremos-en-el-proyecto","title":"\u00bfQu\u00e9 haremos en el proyecto?","text":"<p>Para este proyecto haremos una recopilaci\u00f3n de datos en tiempo casi real de fuentes externas con un web API y lo haremos de forma peri\u00f3dica, utilizando un administrador y planificador de tareas, para almacenarlos en una base de datos relacional.</p> <p>A continuaci\u00f3n hay una ampliaci\u00f3n de estos conceptos.</p>"},{"location":"recopilacion/#datos-desde-fuentes-externas-con-api","title":"Datos desde fuentes externas con API","text":"<p>En el PyX n\u00famero 6 hay una explicaci\u00f3n m\u00e1s amplia sobre los web API y el uso del paquete <code>requests</code> de Python.</p> <p>Hay una gran cantidad de API p\u00fablicos disponibles en Public APIs.</p>"},{"location":"recopilacion/#recoleccion-periodica-de-datos-con-un-planificador-de-tareas","title":"Recolecci\u00f3n peri\u00f3dica de datos con un planificador de tareas","text":"<p>En Python es posible utilizar el paquete Celery como administrador de tareas (task manager) y como un planificador de tareas (task scheduler) que \"calendariza\" tareas en frecuencias especificadas como \"cada 60 segundos\" o seg\u00fan otros criterios, como \"el primer lunes del mes\" o \"al anochecer\".</p> <p>Por tanto, para un flujo de procesamiento de datos en tiempo real o en tiempo casi real podemos usar Celery para recopilar datos de forma continua y peri\u00f3dica. Hay m\u00e1s detalles a continuaci\u00f3n.</p>"},{"location":"recopilacion/#administrador-de-tareas","title":"Administrador de tareas","text":"<p>Celery Worker administra la ejecuci\u00f3n de tareas de forma asincr\u00f3nica entre los \"trabajadores\" (workers) disponibles. Un \"trabajador\" puede ser simplemente un n\u00facleo de la computadora local que est\u00e1 libre para ejecutar una tarea o puede ser un servidor remoto en una configuraci\u00f3n m\u00e1s compleja, por ejemplo.</p> <p>\"Asincr\u00f3nico\" significa que las tareas no bloquean unas a otras. Por ejemplo: en un flujo \"sincr\u00f3nico\" de tareas, una tarea es ejecutada solamente hasta que la anterior haya sido terminada. En el contexto de un administrador de tareas como Celery Worker, un flujo de tareas asincr\u00f3nico permite que m\u00faltiples tareas sean ejecutadas en paralelo, sin esperar a que las tareas anteriores est\u00e9n completas. Celery Worker estar\u00e1 a cargo de \"vigilar\" la cola de ejecuci\u00f3n de las tareas y reportar sus resultados.</p>"},{"location":"recopilacion/#planificador-de-tareas","title":"Planificador de tareas","text":"<p>Celery Beat define los momentos en que las tareas son ejecutadas, es decir, es un \"calendarizador\" o \"planificador\" (scheduler). Esto es \u00fatil para crear tareas en un periodo de tiempo definido como, por ejemplo, \"cada 15 segundos\" o \"cada 12 horas\" o \"todos los d\u00edas a las 2:00 am\" o \"el segundo mi\u00e9rcoles de cada mes\", e inclusive con base en eventos solares, como \"al amanecer\" o \"al mediod\u00eda\" (que var\u00eda seg\u00fan la ubicaci\u00f3n en el planeta y la \u00e9poca del a\u00f1o).</p>"},{"location":"recopilacion/#intermediador-de-mensajes","title":"Intermediador de mensajes","text":"<p>Cuando es necesaria la comunicaci\u00f3n entre procesos en una computadora, es necesario un intermediador de mensajes (message broker) para entregar el mensaje, pues los procesos no pueden comunicarse entre s\u00ed directamente.</p> <p>Redis es un intermediador de mensajes popular que permite varios modelos de comunicaci\u00f3n, como publicaci\u00f3n/suscripci\u00f3n. </p> <p>Redis tiene integraci\u00f3n con Celery, y es necesario para el env\u00edo de la asignaci\u00f3n de las tareas peri\u00f3dicas desde el planificador (Celery Beat) hasta el trabajador (Celery Worker).</p>"},{"location":"recopilacion/#bases-de-datos-e-interfaces-orm","title":"Bases de datos e interfaces ORM","text":"<p>El uso de bases de datos es un \u00e1rea compleja y especializada, sin embargo, hay herramientas en Python que facilitan su gesti\u00f3n.</p> <p>En particular, la recomendaci\u00f3n es utilizar un mapeador relacional de objetos (ORM, Object-Relational Mapping), que representa las tablas y sus datos como una clase en un lenguaje de programaci\u00f3n, habilitando la interacci\u00f3n con la base de datos con el paradigma orientado a objetos, y abstrayendo la especificidad de distintas bases de datos utilizadas.</p> <p>En Python existe SQLAlchemy, un poderoso paquete para interactuar con los DBMS m\u00e1s populares.</p> <p>El ejemplo de la tabla de datos de estudiantes, cursos y matr\u00edcula mostrados anteriormente, puede ser implementado de la siguiente forma.</p> Definici\u00f3n de modelos de la base de datos<pre><code>from sqlalchemy import create_engine, Column, ForeignKey, Integer, Float, String\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker\n\n# Crear la clase base de cada tabla\nBase = declarative_base()\n\n\n# Definir los modelos\nclass Estudiante(Base):\n    __tablename__ = \"estudiantes\"\n\n    estudiante_id = Column(String, primary_key=True)\n    nombre = Column(String)\n    edad = Column(Integer)\n    promedio = Column(Float)\n\n\nclass Curso(Base):\n    __tablename__: = \"cursos\"\n\n    curso_id = Column(String, primary_key=True)\n    nombre = Column(String)\n\n\nclass Matricula(Base):\n    __tablename__ = \"matriculas\"\n\n    estudiante_id = Column(String, ForeignKey(\"estudiantes.estudiante_id\"), primary_key=True)\n    curso_id = Column(String, ForeignKey(\"cursos.curso_id\"), primary_key=True)\n    ciclo = Column(Integer, primary_key=True)\n\n    # Definir relaci\u00f3n de matr\u00edcula con los modelos de estudiante y curso\n    estudiante = relationship(\"Estudiante\")\n    curso = relationship(\"Curso\")\n</code></pre> <p>Aqu\u00ed fueron creadas las tres tablas, donde <code>matriculas</code> hace referencia por medio de llaves for\u00e1neas a las llaves primarias <code>estudiantes.estudiante_id</code> y <code>cursos.curso_id</code>. En esta misma tabla n\u00f3tese tambi\u00e9n que las tres columnas tienen <code>primary_key=True</code>, lo que indica una llave primaria compuesta, para lo cual cada registro debe tener una combinaci\u00f3n \u00fanica de estudiante, curso y ciclo lectivo.</p> <p>Finalmente, hay que crear las tablas estableciendo un <code>engine</code> o referencia a la base de datos a utilizar (en este caso SQLite3) y crear una sesi\u00f3n ligada a ese <code>engine</code>, para poder ejectuar las transacciones deseadas.</p> <pre><code># Crear la conexi\u00f3n a la base de datos SQLite3\nengine = create_engine(f\"sqlite:///{name}\")\nSession = sessionmaker(bind=engine)\nsession = Session()\n\n# Crear la(s) tabla(s) en la base de datos\nBase.metadata.create_all(engine)\n</code></pre> <p>En este proyecto no est\u00e1 determinado un mecanismo fundamental de migraciones, que son necesarias para el caso, completamente usual, en el que hay que realizar una actualizaci\u00f3n en la base de datos cuando hay cambios en los modelos (clases), conservando al mismo tiempo los datos ya almacenados. Por ejemplo, para cambiar el tipo de dato de <code>estudiante_id</code> de <code>String</code> a <code>Integer</code> hay que hacer una migraci\u00f3n. Alembic es la forma de hacerlo con SQLAlchemy, pero no est\u00e1 dentro de los alcances del proyecto.</p> <p>Para el proyecto la recomendaci\u00f3n es utilizar SQLite o PostgreSQL. Una diferencia b\u00e1sica entre ambos es que SQLite3 existe como un archivo binario (por ejemplo, <code>db.sqlite3</code> o <code>data.db</code>) mientras que PostgreSQL es un programa propiamente, instalado en la computadora o servidor. Para proyectos de gran escala PostgreSQL es recomendado, sin embargo SQLite3 tiene capacidad para manejar cientos de millones de datos, as\u00ed que en nuestro proyecto no es un problema. Quiz\u00e1 hay que tener m\u00e1s cuidado de no borrar el archivo \"de un dedazo\".</p>"}]}